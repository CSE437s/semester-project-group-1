{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import airpots2.csv and print head\n",
    "import pandas as pd\n",
    "airports = pd.read_csv('data/airports2.csv')\n",
    "\n",
    "airports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by destination_airport, of which there may be many entries with the same value, and count the number of flights for each, stored in `flights`. make a new dataframe with one entry per destination_airport, and the sum of the number of flights for each.\n",
    "flights = airports.groupby('Destination_airport').size()\n",
    "flights = flights.reset_index(name='flights')\n",
    "\n",
    "# print the top 10 destination_airports by number of flights\n",
    "flights.sort_values('flights', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load airports.json from ../lib/airports.json, load into a df, and print the first 5 entries\n",
    "import json\n",
    "with open('data/airports.json') as f:\n",
    "    airports_json = json.load(f)\n",
    "\n",
    "airports_json = pd.DataFrame(airports_json).T\n",
    "airports_json.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to iata not null, print num unique iata codes\n",
    "airports_json = airports_json[airports_json['iata'].notnull()]\n",
    "airports_json['iata'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the flights df, merge with the airports_json df on the Destination_airport column, and discard those who do not have a match in flights\n",
    "\n",
    "merged = pd.merge(flights, airports_json, left_on='Destination_airport', right_on='iata', how='inner')\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export back to json\n",
    "merged.to_json('data/merged.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process IATA -> desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "client = OpenAI()\n",
    "\n",
    "def getBlurb(city: str, client): # city, state format\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You will be provided with a city in the United States. Please write a 2-3 sentence descriptive blurb, with the goal of providing an accurate description to potential tourists. Mention the area's climate and key destinations.\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": city\n",
    "      }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    "  )\n",
    "\n",
    "  return response.choices[0].message.content\n",
    "\n",
    "# load data/merged.json\n",
    "with open('data/merged.json') as f:\n",
    "    merged = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = getBlurb('Minneapolis, Minnesota', client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "# create failed and blurb list from the json files, if they already exist. otherewise, create empty lists\n",
    "try:\n",
    "    with open('data/failed.txt') as f:\n",
    "        failed = f.read().splitlines()\n",
    "except Exception as e:\n",
    "    failed = []\n",
    "try:\n",
    "    with open('data/blurb.json') as f:\n",
    "        blurb = json.load(f)\n",
    "except Exception as e:\n",
    "    blurb = []\n",
    "\n",
    "for i, row in tqdm(enumerate(merged)):\n",
    "  try:\n",
    "    # check if iata code is already in blurb list\n",
    "    if row['iata'] in [b['iata'] for b in blurb]:\n",
    "      continue\n",
    "    res = getBlurb(row['city'] + ', ' + row['state'], client)\n",
    "    blurb.append({'iata': row['iata'], 'city': row['city'], 'blurb': res})\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "    failed.append(row['iata'])\n",
    "  if i % 30 == 0:\n",
    "    time.sleep(5)\n",
    "    # write to json and failed list in case the process crashes\n",
    "    with open('data/blurb.json', 'w') as f:\n",
    "      json.dump(blurb, f)\n",
    "    with open('data/failed.txt', 'w') as f:\n",
    "        f.write('\\n'.join(failed))\n",
    "\n",
    "with open('data/blurb.json', 'w') as f:\n",
    "    json.dump(blurb, f)\n",
    "with open('data/failed.txt', 'w') as f:\n",
    "    f.write('\\n'.join(failed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimEmbedding(embedding):\n",
    "    return embedding[:512]\n",
    "\n",
    "def getEmbedding(client, text):\n",
    "    res = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "\n",
    "    return trimEmbedding(res.data[0].embedding)\n",
    "\n",
    "\n",
    "import os\n",
    "from supabase import create_client, Client\n",
    "\n",
    "url: str = os.environ.get(\"SUPABASE_URL\")\n",
    "key: str = os.environ.get(\"SUPABASE_KEY\")\n",
    "supabase: Client = create_client(url, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addRows(client, table, rows):\n",
    "    data, count = supabase.table(table).insert(rows).execute()\n",
    "\n",
    "def processJsonEntryToRow(entry):\n",
    "    return {\n",
    "        'iata': entry['iata'],\n",
    "        'location': entry['city'],\n",
    "        'blurb': entry['blurb'],\n",
    "        'embedding': getEmbedding(client, entry['blurb'])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process all entries in the blurb json file to rows, and add to the supabase table. try 30 at a time to avoid rate limiting, and try catch to avoid errors\n",
    "# if there is an error, update the failed_emb.txt file with the iata code\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "try:\n",
    "    with open('data/failed_emb.txt') as f:\n",
    "        failed_emb = f.read().splitlines()\n",
    "except Exception as e:\n",
    "    failed_emb = []\n",
    "\n",
    "# make a succeeded list as well\n",
    "try:\n",
    "    with open('data/succeeded_emb.txt') as f:\n",
    "        succeeded_emb = f.read().splitlines()\n",
    "except Exception as e:\n",
    "    succeeded_emb = []\n",
    "\n",
    "with open('data/blurb.json') as f:\n",
    "    blurb = json.load(f)\n",
    "\n",
    "for i, entry in tqdm(enumerate(blurb)):\n",
    "    rows = []\n",
    "    try:\n",
    "        if entry['iata'] in succeeded_emb:\n",
    "            continue\n",
    "        row = processJsonEntryToRow(entry)\n",
    "        addRows(supabase, 'blurb', [row])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        failed_emb.append(entry['iata'])\n",
    "    if i % 100 == 0:\n",
    "        time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def get_JSON_format(query: str, date: str):\n",
    "    SYSTEM = f\"\"\"\n",
    "    You are a helpful assistant designed turn queries into JSON format. Users will be asking for information about booking flights, \n",
    "    and you will be provided with their natural language query. This may contain multiple components -- primarily it will be a description of \n",
    "    where the users want to go, either natural language (e.g. \"I want to go somewhere warm\"), or specific (e.g. \"I want to go to Orlando\"). \n",
    "    They may also choose to provide information about where they want to depart from, this may be as a city or an airport IATA code. Finally,\n",
    "    there may be information about the date range they are happy to take the departing flight during.\n",
    "    \n",
    "    The JSON has the following keys:\n",
    "    departure_airport: The airport of departure, as an IATA code.\n",
    "    destination_flavor_text: Natural language details about where the user wants to go, to be processed later.\n",
    "    departure_start_date: The first valid date of departure, in the format YYYY-MM-DD.\n",
    "    departure_end_date: The last valid date of departure, in the format YYYY-MM-DD.\n",
    "\n",
    "    Note that today's date is {date}.\n",
    "\n",
    "    If you are not provided with details that would fit to any of these keys, please return that key as an empty string.\n",
    "\n",
    "    Some examples:\n",
    "    Query: \"I want to go to Orlando\"\n",
    "    JSON: \"departure_airport\": \"\", \"destination_flavor_text\": \"I want to go to Orlando\", \"departure_start_date\": \"\", \"departure_end_date\": \"\"\n",
    "\n",
    "    Query: \"I want to go somewhere warm, with a dry desert climate\"\n",
    "    JSON: \"departure_airport\": \"\", \"destination_flavor_text\": \"I want to go somewhere warm, with a dry desert climate\", \"departure_start_date\": \"\", \"departure_end_date\": \"\"\n",
    "\n",
    "    Query: \"I'm leaving from Chicago and I want to go to somewhere cold that is known for skiing\"\n",
    "    JSON: \"departure_airport\": \"ORD\", \"destination_flavor_text\": \"I want to go to somewhere cold that is known for skiing\", \"departure_start_date\": \"\", \"departure_end_date\": \"\"\n",
    "\n",
    "    Query: \"I want to leave in the next week from LAX and go to New York\"\n",
    "    JSON: \"departure_airport\": \"LAX\", \"destination_flavor_text\": \"I want to go to New York\", \"departure_start_date\": \"2024-04-23\", \"departure_end_date\": \"2024-04-30\"\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = \"2024-04-23\"\n",
    "\n",
    "jsonres = get_JSON_format(\"I want to go to Orlando, today or tomorrow\", DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'departure_airport': '',\n",
       " 'destination_flavor_text': 'I want to go to Orlando',\n",
       " 'departure_start_date': '2024-04-23',\n",
       " 'departure_end_date': '2024-04-24'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parse jsonres, a string, into a dictionary\n",
    "import json\n",
    "jsonres = json.loads(jsonres)\n",
    "jsonres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "437",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
